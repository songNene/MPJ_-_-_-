# 프로젝트: Vocabulary Size에 따른 뉴스 분류 성능 비교

## 1. 프로젝트 개요
단어 수(vocabulary size)에 따른 다양한 머신러닝 및 딥러닝 모델의 성능 변화를 분석하고,
최적의 분류 전략을 도출하는 것이 이번 프로젝트의 목표입니다.

---

## 2. 데이터셋
- **데이터 출처**: Reuters 뉴스 기사 데이터셋 (`keras.datasets.reuters`)
- **데이터 구성**: 뉴스 기사 텍스트 및 해당 기사에 대한 주제(46개 클래스)

---

## 3. 실험 구성
| 항목 | 설명 |
|------|------|
| 벡터화 방법 | `Tokenizer`로 정수 인덱스 시퀀스 생성 후 `pad_sequences`로 길이 정규화 |
| 단어 수 설정 | `num_words = 500`, `5000`, `10000`, `None` |
| 적용 모델 (ML) | 나이브 베이즈, CNB, 로지스틱 회귀, 선형 SVM, 결정 트리, 랜덤 포레스트, GBDT, 보팅 |
| 적용 모델 (DL) | Dense Neural Network (DNN), Recurrent Neural Network (RNN) |
| 평가 지표 | Accuracy, F1-score (weighted) |

---

## 4. 실험 결과 요약 (ML)

### 단어 수별 모델 성능 비교 (Accuracy / F1-score)

| 모델 | num_words=10000 | num_words=5000 | num_words=None | num_words=500 |
|------|-----------------|----------------|----------------|----------------|
| 나이브 베이즈 | 0.6567 / 0.5764 | 0.6732 / 0.6013 | 0.5997 / 0.5045 | 0.6589 / 0.6054 |
| CNB | 0.7707 / 0.7456 | 0.7707 / 0.7459 | 0.7649 / 0.7346 | 0.7074 / 0.6591 |
| 로지스틱 회귀 | 0.8085 / 0.8022 | 0.8059 / 0.8000 | 0.8110 / 0.8055 | 0.7212 / 0.7173 |
| 선형 SVM | 0.7880 / 0.7831 | 0.7774 / 0.7734 | 0.7871 / 0.7834 | 0.7056 / 0.7086 |
| 결정 트리 | 0.6202 / 0.5776 | 0.6180 / 0.5730 | 0.6211 / 0.5769 | 0.6108 / 0.5374 |
| 랜덤 포레스트 | 0.6740 / 0.6429 | 0.6674 / 0.6351 | 0.6544 / 0.6226 | 0.6981 / 0.6728 |
| GBDT | 0.7684 / 0.7647 | 0.7667 / 0.7605 | 0.7680 / 0.7627 | 0.7430 / 0.7342 |
| 보팅 | 0.7983 / 0.7939 | 0.7985 / 0.7965 | 0.7996 / 0.7942 | 0.7546 / 0.7460 |

---

## 5. Word2Vec 기반 성능 비교 (ML vs DL)

| 모델 | Accuracy | F1-score |
|------|----------|----------|
| XGBoost | 0.7266 | 0.7088 |
| 로지스틱 회귀 | 0.7106 | 0.6823 |
| Dense NN | 0.6830 | 0.6597 |
| RNN | 0.7106 | 0.6823 |

---

## 6. 결론

- 단어 수가 지나치게 작을 경우(`num_words=500`), 전반적으로 성능 저하가 발생하였으며, 특히 결정트리 계열 모델에서 두드러짐.
- 로지스틱 회귀, CNB, 보팅 모델은 전 범위에서 안정적인 성능을 보였으며, CNN 등의 딥러닝 모델은 큰 성능 우위는 없었음.
- Word2Vec 기반에서는 XGBoost와 RNN이 유사한 정확도를 보이며, 딥러닝 대비 학습 효율 측면에서 ML 모델이 경쟁력을 가짐.

---

## 7. 실행 환경
- Python 3.10+
- TensorFlow / Keras
- Scikit-learn
- Gensim (Word2Vec)
